{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python373jvsc74a57bd09164a3399a70d355c381b62813f30880ed90ca5a6f321bf0d85375640bda7ee5",
   "display_name": "Python 3.7.3 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Approximate Inference in probabilistic modeling\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "Exact inference in probabilistic models is usually not possible, due to intractability of expectations or any other quantity involving integrals which are not analytically computable. Hence, algorithms which are able to perform inference approximately, are widely used. 2 main classes of approximate inference algorithms are Variational Inference (VI) based methods, and Sampling based methods.\n",
    "\n",
    "In this notebook, emphasis will be on demonstrating the efficiency and usefulness of such approximate inference algorithms for probabilistic modeling tasks. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 2. Sampling based methods\n",
    "### 2.1 Rejection Sampling\n",
    "\n",
    "The most basic algorithm used to sample from a distribution which is not fully tractable, is **Rejection Sampling**. Consider a probability distribution $p(x) = \\frac{\\tilde{p}(x)}{Z_p}$, where $Z_p$ is intractable. However, we can evaluate $\\tilde{p}(x) \\,\\, \\forall x \\, \\in \\, \\text{Support}(\\tilde{p}(x))$.\n",
    "The algorithm is simple : At every iteration $t$, we sample $x^{(t)}$ from a proposal distribution $q(x)$ and $u$ from $U[0, Mq(x)]$, where M is a constant such that $Mq(x) > \\tilde{p}(x) \\,\\, \\forall x \\, \\in \\, \\text{Support}(\\tilde{p}(x))$. The support of the proposal distribution should be atleast the support of $\\tilde{p}(x)$. \n",
    "\n",
    "If $u \\geq \\tilde{p}(x)$, we add $x^{(t)}$ to the set of samples, else it is rejected. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 2.2 Monte Carlo sampling\n",
    "\n",
    "This method is used to compute intractable expectations approximately. For commputing expectation of $f(x)$ over a distribution $p(x)$ (which can be sampled from), we have $$E_p[f(x)] = \\int f(x) p(x) dx \\\\\n",
    "                                E_p[f(x)] \\approx \\frac{1}{S} \\sum_{s=1}^S f(x^{(s)}) \\quad ; \\quad x^{(s)} \\sim p(x)$$\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 2.3 Importance sampling\n",
    "\n",
    "This method is used to compute intractable expectations approximately, where we cannot sample directly from the target distribution.\n",
    "Consider a function $f(x)$, whose expectation we wish to calculate, over a distribution $p(x)$. Suppose that the quantity $$E_p[f(x)] = \\int f(x) p(x) dx$$ is intractable. We use a proposal distribution $q(x)$ (again defined atleast over the support of $p(x)$) so that the integral above is written as $$E_p[f(x)] = \\int f(x) \\frac{p(x)}{q(x)} q(x) dx \\\\\n",
    "                          = E_q[f(x)w(x)]$$\n",
    "This quantity can be easily approximated using Monte Carlo sampling such that $$E_q[f(x)w(x)] = \\frac{1}{S}\\sum_{s=1}^S f(x^{(s)})w(x^{(s)}) \\quad ; \\quad \\{x^{(s)}\\}_{s=1}^S \\sim q(x).$$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "** *Note that Monte Carlo sampling and Importance sampling are not designed to sample from a probability distribution, but only to compute expectations over a given distribution.* **\n",
    "\n",
    "The above algorithms are useful till the problems involved are of low-dimension and \"simple\". As soon as the complexity increases, the above methods fail to provide a solution to the approximate inference problem.\n",
    "\n",
    "Hence we consider MCMC based sampling algorithms which can generalize well to problems of increased complexity."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### Quick Detour - Markov Chains\n",
    "\n",
    "Markov chains are an interesting and important concept in probability, where we model a series of outcomes, with the current state based only on the previous outcome. Formally $$p(x_t \\, | \\, x_1,x_2,...,x_{t-1}) = p(x_t\\, | \\, x_{t-1})$$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 2.4 Metropolis-Hastings (MH) Algorithm\n",
    "\n",
    "This is one of the most important MCMC based sampling methods. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 2.5 Gibbs Sampling\n",
    "\n",
    "Another important sampling algorithm"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}